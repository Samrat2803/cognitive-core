# Master Political Analyst Agent

LangGraph-based master agent for the Political Analyst Workbench.

## Architecture

```
START
  â†“
Conversation Manager  (Initialize context, manage history)
  â†“
Strategic Planner     (Analyze query, plan tool usage)
  â†“
Tool Executor         (Execute Tavily tools, call sub-agents)
  â†“
Decision Gate         (Check if more data needed)
  â†“ [loop if needed]
  â†“ [continue if ready]
Response Synthesizer  (Compile final response)
  â†“
END
```

## Nodes

### 1. **Conversation Manager**
- Manages conversation history
- Initializes session context
- Tracks conversation state

### 2. **Strategic Planner**
- Analyzes user query intent
- Determines which tools to use
- Plans execution strategy
- Uses GPT-4o-mini for planning

### 3. **Tool Executor**
- Executes Tavily tools:
  - **Search**: Real-time web search
  - **Extract**: Content extraction from URLs
  - **Crawl**: Deep website crawling
- Calls sub-agents:
  - **Sentiment Analyzer**: Multi-country sentiment analysis
  - Future: Fact checker, source credibility, etc.

### 4. **Decision Gate**
- Evaluates if sufficient information gathered
- Routes to retry tools or proceed to synthesis
- Enforces iteration limits (max 3)

### 5. **Response Synthesizer**
- Compiles results from all sources
- Formats user-friendly response
- Adds citations and sources
- Uses GPT-4o-mini for synthesis

## Tools Available

### Direct Tavily Tools
- `tavily_search`: Real-time web search
- `tavily_extract`: Extract content from URLs
- `tavily_crawl`: Deep crawl websites

### Sub-Agents
- `sentiment_analysis_agent`: Comprehensive geopolitical sentiment analysis (to be implemented)
- `fact_checker_agent`: Claim verification (future)
- `source_credibility_agent`: Source reliability assessment (future)

## Usage

### Basic Usage

```python
from langgraph_master_agent.main import MasterPoliticalAnalyst

# Initialize
agent = MasterPoliticalAnalyst()

# Process query
result = agent.process_query_sync("What's happening in Gaza?")

print(result["response"])
print(f"Confidence: {result['confidence']}")
print(f"Citations: {len(result['citations'])}")
```

### Async Usage

```python
import asyncio
from langgraph_master_agent.main import MasterPoliticalAnalyst

async def main():
    agent = MasterPoliticalAnalyst()
    result = await agent.process_query("Analyze US-China relations")
    print(result["response"])

asyncio.run(main())
```

### With Real-time Callbacks

```python
def update_ui(result):
    print(f"Tools used: {result['tools_used']}")
    print(f"Progress: {result['iterations']}")

agent = MasterPoliticalAnalyst(update_callback=update_ui)
result = agent.process_query_sync("Latest climate policy updates")
```

## Running Tests

```bash
cd Political_Analyst_Workbench

# Activate venv if available
source .venv/bin/activate

# Run master agent
python langgraph_master_agent/main.py
```

## Configuration

Edit `config.py` to customize:
- LLM model and temperature
- Max iterations
- Tavily search settings
- Tool registry

## State Schema

The agent maintains comprehensive state through `MasterAgentState`:

```python
{
    "conversation_history": [...],
    "current_message": "user query",
    "task_plan": "planned actions",
    "tools_to_use": ["tavily_search"],
    "tool_results": {...},
    "sub_agent_results": {...},
    "final_response": "formatted response",
    "citations": [...],
    "confidence_score": 0.85,
    "execution_log": [...],
    "metadata": {...}
}
```

## LangFuse Observability

All nodes are decorated with `@observe` for LangFuse tracing:
- Track execution flow
- Monitor LLM calls
- Debug issues
- Analyze performance

View traces at: `http://localhost:3761`

## Next Steps

1. âœ… Master agent infrastructure complete
2. ğŸ“ Implement sentiment analyzer sub-agent
3. ğŸ”— Connect sub-agent to master
4. ğŸ¨ Build UI for visualization
5. ğŸ§ª Add comprehensive tests

## File Structure

```
langgraph_master_agent/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ README.md
â”œâ”€â”€ state.py              # State schema
â”œâ”€â”€ config.py             # Configuration
â”œâ”€â”€ graph.py              # Graph definition
â”œâ”€â”€ main.py               # Entry point
â”œâ”€â”€ nodes/
â”‚   â”œâ”€â”€ conversation_manager.py
â”‚   â”œâ”€â”€ strategic_planner.py
â”‚   â”œâ”€â”€ tool_executor.py
â”‚   â”œâ”€â”€ decision_gate.py
â”‚   â””â”€â”€ response_synthesizer.py
â””â”€â”€ tools/
    â”œâ”€â”€ tavily_direct.py
    â””â”€â”€ sub_agent_caller.py
```

## Dependencies

See `../requirements.txt` for full dependencies:
- langgraph
- langchain-openai
- httpx
- python-dotenv
- langfuse (optional, for observability)

